
```{r setup, message=FALSE}
library(tidyverse)
library(bggjphd)
library(metill)
library(sf)

theme_set(theme_bggj())
```


## Background

<br>

![](images/lifeyrir2.png){fig-align=center .r-stretch}

## Extreme Precipitation

![](images/phd_nafn.png){fig-align=center width=50% .m-0 .p-0}

::: {layout="[50,50]"}

![](images/flod1.jpg){fig-align=center width=450px .mt-0 .pt-0}

![](images/flod2.jpg){fig-align=center width=450px .mt-0 .pt-0}

:::

## United Kingdom Climate Projections

![](images/max_precip.png){fig-align=center}

$$
180 \times 244 \times 24 \times 365 \times 60 \approx 23 \cdot 10^9
$$

## Use the maximum (Luke)



![](images/dreifing_maximum.gif){fig-align=center}

$$
180 \times 244 \times 60 \approx 2.6 \cdot 10^6
$$

## Statistics of Extremes

<br>

::: {layout="[40,60]"}

![Fisher & Tippett](images/fishertippett.jpg){fig-align=center}

![](images/theorem3.png){fig-align=center}

:::

## Central Limits vs Extremes

$$
\scriptsize{
\begin{aligned}
X_1, \dots, X_n &\sim F(x) \\
S_n &= X_1 + \dots + X_n \\
M_n &= \max{\{X_1, \dots, X_n\}}
\end{aligned}
}
$$

<br>

::: {columns}

::: {.column width="49%"}

Central Limit Problem

$$
\scriptsize{
\frac{S_n - a_n}{b_n} \rightarrow G(x)?
}
$$

:::

::: {.column width="49%"}

Extreme Value Problem

$$
\scriptsize{
\frac{M_n - a_n}{b_n} \rightarrow G(x)?
}
$$
:::

:::

## Exponential example:  $F(x) = 1 - e^{-x}$

$$
\scriptsize{
\begin{aligned}
P\left(
\frac{M_n - a_n}{b_n} \leq x
\right) =
P\left(M_n \leq a_n + b_nx \right) =
\left[1 - e^{-(a_n + b_nx)}\right]^n
\end{aligned}
}
$$

Choose 
$$
\scriptsize{
a_n = \ln(n) = F^{-1}(1 - n^{-1})
\qquad
b_n = 1
}
$$

Then we get

$$
\scriptsize{
P\left(M_n \leq a_n + b_nx \right) =
\left[1 - n^{-1}e^{-x}\right]^n \rightarrow \exp{\{-e^{-x}\}}
}
$$

This is the [Gumbel distribution](https://en.wikipedia.org/wiki/Gumbel_distribution)

## Generalized Extreme Value Distribution



::: {.columns}

::: {.column width="60%"}

$$
F(x) = e^{-\left[
1 + \xi \left(
\frac{x - \tilde{\mu}}{\sigma}
\right)
\right]^{-1/\xi}
} \\
\tilde\mu = \mu \cdot [1 + \Delta \cdot (t - t_0)]
$$

<p style='color:#99000d;text-align:center'>Station 1 $(\mu_1, \sigma_1, \xi_1, \Delta_1)$</p>

<p style='color:#ff7f00;text-align:center'>Station 2 $(\mu_2, \sigma_2, \xi_2, \Delta_1)$</p>

<p style='color:#0570b0;text-align:center'>Station 3 $(\mu_3, \sigma_3, \xi_3, \Delta_1)$</p>

:::

::: {.column width="40%"}

![](images/stations.png)

:::

:::

## Max(-and-Smooth)

$$
\begin{aligned}
L (\eta | y) &= \prod_i^N L (\eta_i | y_i)\\
&= \prod_i^N \mathrm{Normal}(\eta_i | \hat\eta_i, \Sigma_{\eta_i y_i}) \\
&= \mathrm{Normal}(\eta | \hat\eta, \Sigma_{\eta y})
\end{aligned}
$$

## (Max-and)-Smooth

$$
\tiny{
f(\mu, \sigma, \xi, \Delta) \sim \mathrm{Normal} 
\left(
\begin{bmatrix}
\mu_\mu \\ \mu_\sigma \\ \mu_\xi \\ \mu_\Delta
\end{bmatrix},
\begin{bmatrix}
 \tau_\mu Q_u & \\
 & \tau_\sigma Q_u \\ 
 & & \tau_\xi Q_u \\
 & & & \tau_\Delta Q_u
\end{bmatrix}
\right)
}
$$

$$
\tiny{
\begin{aligned}
(\mu_\mu, \mu_\sigma, \mu_\xi, \mu_\Delta) &\sim \mathrm{SensiblePrior(\theta_\mu)} \\
(\tau_\mu, \tau_\sigma, \tau_\xi, \tau_\Delta) &\sim \mathrm{SensiblePrior(\theta_\tau)}
\end{aligned}
}
$$

## Spatial Model

![](images/qu.png){fig-align=center width=50%}

::: {columns}

::: {.column width="49%"}



```{r}
#| echo: true
matrix(
    1:9,
    nrow = 3, ncol = 3
)
```



:::

::: {.column width="49%"}

```{r}
#| echo: true
make_Q_u(3, 3)
```

:::

:::

## Sampler

* $43920 \cdot 4 = 175680$ station-specific parameters
* Want to run sampler for thousands of iterations
* Save each iteration into a collection of parquet files
    - One folder for each chain
    - One folder for each iteration
* Query the posterior like a database

## Parquet Posterior

```{r, eval = FALSE}
#| echo: true
#| eval: false
library(arrow)
mcmc <- open_dataset("data/posterior") |> to_duckdb()
mcmc
```




![](images/parquet.png){fig-align=center}



## Still a problem

![](images/copula_rannis.png){fig-align=center}

## Enter Copulas

![](images/copula_trade.png){fig-align=center}

## Steps

![](images/copula_rannis.png){fig-align=center}

1. Get posterior of station-wise GEV parameters
2. Transform observed data to $[0, 1]$ using GEV params
3. Transform $[0, 1]$ to t-distribution
4. Calculate $Q$, the precision matrix of our t-distribution


## Previously on Binni's PhD

![](images/mean_neighbor_effect_multivariate.png){fig-align=center}

## Previously on Binni's PhD

![](images/spatial_dist_by_neighbor_type_mcmc.png){fig-align=center}


## Results (no spatial smoothing)

<br>

![](images/param_results_ml.png){fig-align=center width="60%"}

## Results (with spatial smoothing)

<br>


![](images/param_results_mcmc.png){fig-align=center width="60%"}


## Summary

<br>

* Large dataset with many parameters
* Max-and-Smooth makes things easier
* Copulas to make data-level correlations

<br>

[Code for slides and figures](https://github.com/bgautijonsson/math_may_23)

[Code and data for my PhD](https://github.com/bgautijonsson/bggjphd)

[Website where I update documentation and results](https://bggj.is/phd/)
